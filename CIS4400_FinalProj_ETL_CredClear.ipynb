{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50c6c0c4",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Setting Up</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29497fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up; import necessary packages/libraries\n",
    "import os\n",
    "#!pip install sodapy\n",
    "from sodapy import Socrata\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#!pip install --upgrade google-cloud-storage\n",
    "#!pip install --upgrade google-cloud-bigquery\n",
    "#!pip install pandas-gbq\n",
    "from google.cloud import bigquery\n",
    "from pandas.io import gbq\n",
    "\n",
    "\n",
    "#make sure to set environment var for GOOGLE_APPLICATION_CREDENTIALS\n",
    "#https://cloud.google.com/bigquery/docs/quickstarts/quickstart-client-libraries\n",
    "#os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = CREDENTIALS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f23dec",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Extract & Transform for Collisions Dataset</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de74ac58",
   "metadata": {},
   "source": [
    "## Extracting - Collisions Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "959a1d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#credentials needed to pull data from the API\n",
    "domain = \"data.cityofnewyork.us\"\n",
    "collisions_data_id = \"h9gi-nx95\"\n",
    "token = \"TOKEN\"\n",
    "\n",
    "#set up a connection using the credentials\n",
    "client_collisions = Socrata(domain,token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f730fb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check metadata; make sure we're pulling the right dataset\n",
    "#also helps with familiarizing ourselves with the dataset\n",
    "metadata_collisions = client_collisions.get_metadata(collisions_data_id)\n",
    "\n",
    "#metadata #<- view metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fe37afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query applied when pulling the data from the api\n",
    "#filter to only pull records older than Dec 31, 2018; start from 2019\n",
    "collisions_query = \"\"\"\n",
    "    select collision_id,\n",
    "        crash_date, \n",
    "        crash_time, \n",
    "        borough, \n",
    "        zip_code,\n",
    "        number_of_persons_injured, number_of_persons_killed,\n",
    "        number_of_pedestrians_injured, number_of_pedestrians_killed,\n",
    "        number_of_cyclist_injured, number_of_cyclist_killed,\n",
    "        number_of_motorist_injured, number_of_motorist_killed,\n",
    "        contributing_factor_vehicle_1, contributing_factor_vehicle_2, contributing_factor_vehicle_3,\n",
    "        vehicle_type_code1, vehicle_type_code2, vehicle_type_code_3\n",
    "    where crash_date > '2018-12-31'\n",
    "    limit 100000000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9451c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull data from the API\n",
    "#pass in query towards the request\n",
    "pull_collisions_data = client_collisions.get(collisions_data_id, query = collisions_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae6ff375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe for the collisions data pulled from the API\n",
    "collisions_df = pd.DataFrame(pull_collisions_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53c84940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all NaN values with Unspecified\n",
    "collisions_df.fillna(\"Unspecified\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f107601",
   "metadata": {},
   "source": [
    "## Transforming - Collisions Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fdf74ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert crash_date col to a string\n",
    "collisions_df['crash_date'] = collisions_df['crash_date'].astype(str)\n",
    "\n",
    "#create datetime column; combine crash_dat col and crash_time col and then convert the string into a datetime\n",
    "collisions_df['date_time']=pd.to_datetime(collisions_df[\"crash_date\"]+ ' '+collisions_df[\"crash_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55c2e374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Year, Month, Day, and Week columns; extract from crash_date col\n",
    "collisions_df[\"year\"] = collisions_df[\"date_time\"].dt.year\n",
    "\n",
    "collisions_df[\"month\"] = collisions_df[\"date_time\"].dt.month\n",
    "collisions_df[\"month\"] = collisions_df[\"month\"].apply(lambda x: calendar.month_abbr[x])\n",
    "\n",
    "collisions_df[\"day\"] = collisions_df[\"date_time\"].dt.day\n",
    "\n",
    "collisions_df[\"week\"] = collisions_df[\"date_time\"].dt.isocalendar().week\n",
    "collisions_df[\"week\"] = collisions_df[\"week\"].astype(int) #<---- convert dtype from UINT32 to int64; will cause issues with pyarrow if we don't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e064fff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function that will denote if timestamp is AM or PM\n",
    "def period_converter(x):\n",
    "    hour = x.hour\n",
    "    if hour < 12:\n",
    "        period =\"AM\"\n",
    "    else:\n",
    "        period =\"PM\"\n",
    "        \n",
    "    return period\n",
    "\n",
    "#create Period column; apply period_converter to all rows in crash_time column\n",
    "collisions_df[\"period\"] = collisions_df[\"date_time\"].apply(lambda x: period_converter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f212d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary containing current col names and what they will be changed to\n",
    "col_rename = {\"number_of_persons_injured\": \"persons_injured\",\n",
    "             \"number_of_persons_killed\": \"persons_killed\",\n",
    "             \"number_of_pedestrians_injured\": \"pedestrians_injured\",\n",
    "             \"number_of_pedestrians_killed\": \"pedestrians_killed\",\n",
    "             \"number_of_cyclist_injured\": \"cyclists_injured\",\n",
    "             \"number_of_cyclist_killed\": \"cyclists_killed\",\n",
    "             \"number_of_motorist_injured\": \"motorists_injured\",\n",
    "             \"number_of_motorist_killed\": \"motorists_killed\",\n",
    "             \"vehicle_type_code_3\": \"vehicle_type_code3\",\n",
    "             \"contributing_factor_vehicle_1\":\"contributing_factor_vehicle1\",\n",
    "             \"contributing_factor_vehicle_2\":\"contributing_factor_vehicle2\",\n",
    "             \"contributing_factor_vehicle_3\":\"contributing_factor_vehicle3\"}\n",
    "\n",
    "#rename columns in the df\n",
    "collisions_df.rename(columns = col_rename, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e83ce7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearrange columns\n",
    "collisions_df = collisions_df.reindex(columns=[\"collision_id\",\n",
    "                              \"crash_date\", \"crash_time\", \"date_time\",\n",
    "                              \"year\",\"month\",\"week\", \"day\", \"period\",\n",
    "                              \"borough\", \"zip_code\",\n",
    "                              \"contributing_factor_vehicle1\", \"contributing_factor_vehicle2\", \"contributing_factor_vehicle3\",\n",
    "                              \"vehicle_type_code1\", \"vehicle_type_code2\",\"vehicle_type_code3\",\n",
    "                               \"persons_injured\", \"persons_killed\",\n",
    "                               \"pedestrians_injured\",\"pedestrians_killed\",\n",
    "                               \"cyclists_injured\",\"cyclists_killed\",\n",
    "                               \"motorists_injured\", \"motorists_killed\"\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fd3077",
   "metadata": {},
   "source": [
    "### Creating Dimension Tables (Collisions/Crashes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d3e3855",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Creating dimension table ids\n",
    "\"\"\"\n",
    "\n",
    "#get index and use the numbers for numerical portion of the dimension table ids\n",
    "index_nums_collisions =collisions_df.index.tolist()\n",
    "\n",
    "#create function for generating id col for dim tables\n",
    "#df = dim table dataframe, denoter = letter portion of id, id_col_name = name of id col, index_list = list with index #s from df\n",
    "def dim_id_generator(df,denoter,id_col_name,index_list): #id_col_name is a str\n",
    "    id_col_name_str = str(f'{id_col_name}')\n",
    "    table_id_list = [f\"{denoter}{x+1}\" for x in index_list]\n",
    "    df[id_col_name_str] = table_id_list\n",
    "    df = df\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5d09110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create date dim table\n",
    "dim_crashdate = collisions_df[[\"date_time\",\"year\", \"month\", \"week\", \"day\", \"period\"]]\n",
    "\n",
    "#create location dimtable\n",
    "dim_crashlocation = collisions_df[[\"borough\", \"zip_code\"]]\n",
    "\n",
    "#create contributing factor dim table\n",
    "dim_contributingfactor = collisions_df[[\"contributing_factor_vehicle1\", \"contributing_factor_vehicle2\", \n",
    "                                       \"contributing_factor_vehicle3\",\n",
    "                                       \"vehicle_type_code1\", \"vehicle_type_code2\",\"vehicle_type_code3\"]]\n",
    "#create casualties dim table\n",
    "dim_casualties = collisions_df[[\"persons_killed\",\"persons_injured\",\n",
    "                                \"pedestrians_killed\",\"pedestrians_injured\",\n",
    "                                \"cyclists_killed\", \"cyclists_injured\",\n",
    "                                \"motorists_killed\", \"motorists_injured\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb275e1a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#generate id col for the dimension tables\n",
    "\n",
    "dim_id_generator(dim_casualties,\"CA\",\"dim_casualties_id\", index_nums_collisions)\n",
    "dim_id_generator(dim_contributingfactor,\"CF\",\"dim_contributingfactor_id\", index_nums_collisions)\n",
    "dim_id_generator(dim_crashdate, \"CD\",\"dim_crashdate_id\", index_nums_collisions)\n",
    "dim_id_generator(dim_crashlocation,\"CL\", \"dim_crashlocation_id\",index_nums_collisions);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6782dcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearrange columns in the dim table dataframes\n",
    "dim_tables_list = [dim_crashdate,dim_crashlocation,dim_contributingfactor, dim_casualties]\n",
    "\n",
    "#function for rearranging columns in the dim table dataframes\n",
    "#dim_table = dim table df, id_col_name = col header name for id col\n",
    "def column_arranger(dim_table, id_col_name):\n",
    "    first_col = dim_table.pop(id_col_name)\n",
    "    dim_table.insert(0,id_col_name,first_col)\n",
    "    return dim_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85ef47bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rearrange cols so that id col is first col\n",
    "column_arranger(dim_crashdate, \"dim_crashdate_id\")\n",
    "column_arranger(dim_crashlocation, \"dim_crashlocation_id\")\n",
    "column_arranger(dim_contributingfactor, \"dim_contributingfactor_id\")\n",
    "column_arranger(dim_casualties, \"dim_casualties_id\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f675f03",
   "metadata": {},
   "source": [
    "\n",
    "<h1 align=\"center\">Extract & Transform for 311 Traffic Lights Complaints</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59faa1a",
   "metadata": {},
   "source": [
    "## Extracting - 311 Traffic Lights Complains Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b44d8ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#credentials needed to pull data from the API\n",
    "domain = \"data.cityofnewyork.us\"\n",
    "complaints311_id = \"erm2-nwe9\"\n",
    "token = \"TOKEN\"\n",
    "\n",
    "#set up a connection using the credentials\n",
    "client_complaints311 = Socrata(domain,token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54797fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query: pulling all records from the start of 2019 where the complaints were about street/traffic lights\n",
    "trafficlights311_query = \"\"\"\n",
    "    select unique_key, complaint_type, descriptor, address_type,\n",
    "        borough, incident_zip,\n",
    "        created_date\n",
    "    where created_date > '2018-12-31'\n",
    "    and complaint_type = \"Street Light Condition\"\n",
    "    or complaint_type = \"Traffic Light Condition\"\n",
    "    limit 100000000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4552ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulling traffic lights 311 dataset\n",
    "pull_trafficlights311_data = client_complaints311.get(complaints311_id, query = trafficlights311_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77dc899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe of the trafficlights 311 data pulled from API\n",
    "#replace NaN Values with \"Unspecified\"\n",
    "trlights311_df = pd.DataFrame(pull_trafficlights311_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dddfa8",
   "metadata": {},
   "source": [
    "## Transforming - 311 Traffic Lights Complaints Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0dcbde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all NaN values with \"Unspecified\"\n",
    "trlights311_df.fillna(\"Unspecified\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b87048f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert created_date col to datetime\n",
    "trlights311_df[\"created_date\"] = pd.to_datetime(trlights311_df[\"created_date\"], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82a0b870",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create Year, Month, Day, and Week columns; extract from created_date col\n",
    "trlights311_df[\"year\"] = trlights311_df[\"created_date\"].dt.year\n",
    "\n",
    "trlights311_df[\"month\"] = trlights311_df[\"created_date\"].dt.month\n",
    "trlights311_df[\"month\"] = trlights311_df[\"month\"].apply(lambda x: calendar.month_abbr[x])\n",
    "\n",
    "trlights311_df[\"week\"] = trlights311_df[\"created_date\"].dt.isocalendar().week\n",
    "trlights311_df[\"week\"] = trlights311_df[\"week\"].astype(int) #<---- convert dtype from UINT32 to int64; will cause issues with pyarrow if we don't\n",
    "\n",
    "trlights311_df[\"day\"] = trlights311_df[\"created_date\"].dt.day\n",
    "\n",
    "#create Period column; use period_converter function - apply to all rows in created_time column\n",
    "trlights311_df[\"period\"] = trlights311_df[\"created_date\"].apply(lambda x: period_converter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3ec595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename incident_zip to zip_code\n",
    "trlights311_df.rename(columns = {\"incident_zip\":\"zip_code\",\"created_date\":\"complaint_date\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c581dc3c",
   "metadata": {},
   "source": [
    "### Creating Dimension Tables (311 Traffic Light Complaints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6abd982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create complaint dim table\n",
    "dim_311complaint = trlights311_df[[\"complaint_type\",\"descriptor\"]]\n",
    "\n",
    "#create complaint location dim table\n",
    "dim_311location = trlights311_df[[\"borough\",\"zip_code\"]]\n",
    "\n",
    "#create complaint date dim table\n",
    "#since pyarrow has trouble processing dataframes with multiple types we create a new data frame instead of subsetting\n",
    "dim_311date = trlights311_df[[\"complaint_date\",\"year\",\"month\",\"week\",\"day\",\"period\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83aa1024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index of trlights_df\n",
    "index_nums_trlights311 = trlights311_df.index.tolist()\n",
    "\n",
    "#create id col for the dim tables for 311 traffic light complaints using dim_id_generator function\n",
    "#df = dim table dataframe, denoter = letter portion of id, id_col_name = name of id col, index_list = list with index #s from df\n",
    "#def dim_id_generator(df,denoter,id_col_name,index_list): # denoter &id_col_name are strings\n",
    "\n",
    "dim_id_generator(dim_311complaint,\"TC\",\"dim_311complaint_id\",index_nums_trlights311)\n",
    "dim_id_generator(dim_311location,\"TL\",\"dim_311location_id\",index_nums_trlights311)\n",
    "dim_id_generator(dim_311date,\"TD\",\"dim_311date_id\",index_nums_trlights311);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b9a8022",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearranging columns in the dim table dataframes so that id col is first using column_arranger\n",
    "#dim_table = dim table df, id_col_name = col header name for id col\n",
    "#def column_arranger(dim_table, id_col_name): #id_col_name is a str\n",
    "\n",
    "column_arranger(dim_311complaint, \"dim_311complaint_id\")\n",
    "column_arranger(dim_311date, \"dim_311date_id\")\n",
    "column_arranger(dim_311location,\"dim_311location_id\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb1bb5d",
   "metadata": {},
   "source": [
    "\n",
    "<h1 align=\"center\">Loading Collisions/Crashes and 311 Traffic Lights Complaints to Google BigQuery</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "280bbfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate bigquery client\n",
    "client = bigquery.Client(project='cis4400-assignments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9a39f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for porting dim_tables to GBQ\n",
    "# df = dim table, table_name = table name\n",
    "def port_table_to_gbq(table_name,df): #table_name is a string\n",
    "    destination_table_path = f\"cis4400_finalproject.{table_name}\"\n",
    "    job = df.to_gbq(destination_table = destination_table_path,\n",
    "             project_id = \"cis4400-assignments\",\n",
    "             if_exists= \"replace\")\n",
    "    return job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40b044f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#list containing the dim tables\n",
    "dim_tables_container = {\"dim_311complaint\":dim_311complaint, \n",
    "                        \"dim_311location\":dim_311location, \n",
    "                        \"dim_311date\":dim_311date,\n",
    "                        \"dim_crashdate\":dim_crashdate, \n",
    "                        \"dim_crashlocation\":dim_crashlocation, \n",
    "                        \"dim_contributingfactor\":dim_contributingfactor, \n",
    "                        \"dim_casualties\":dim_casualties}\n",
    "\n",
    "#port the dim tables to GBQ using the port_table_to_gbq function\n",
    "for tablename,dimtable in dim_tables_container.items():\n",
    "    port_table_to_gbq(tablename, dimtable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
